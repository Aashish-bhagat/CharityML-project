{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda 2019.03\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\anaconda 2019.03\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 361 samples F Score => train: 0.8 test: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda 2019.03\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 3617 samples F Score => train: 0.86 test: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda 2019.03\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 36177 samples F Score => train: 0.88 test: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda 2019.03\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier 361 samples F Score => train: 0.87 test: 0.86\n",
      "SGDClassifier 3617 samples F Score => train: 0.87 test: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda 2019.03\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\anaconda 2019.03\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier 36177 samples F Score => train: 0.89 test: 0.89\n",
      "KNeighborsClassifier 361 samples F Score => train: 0.9 test: 0.86\n",
      "KNeighborsClassifier 3617 samples F Score => train: 0.89 test: 0.87\n",
      "KNeighborsClassifier 36177 samples F Score => train: 0.91 test: 0.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from time import time\n",
    "#import visuals as vs\n",
    "%matplotlib inline\n",
    "data=pd.read_csv('census.csv')\n",
    "#print(data)\n",
    "income=data['income']\n",
    "#print(income)\n",
    "feature=data.drop('income',axis=1)\n",
    "#print(feature.head())\n",
    "skewed=['capital-gain','capital-loss']\n",
    "#print(data[skewed[0]])\n",
    "#plt.plot(data[skewed[0]],income,'o')\n",
    "feature_data=feature\n",
    "#print(feature_data.head())\n",
    "feature_data[skewed]=feature_data[skewed].apply(lambda x: np.log(x+1))\n",
    "feature_final=pd.get_dummies(feature_data)\n",
    "r=feature_final\n",
    "#print(r.head())\n",
    "#print(r)\n",
    "#print(feature_data)\n",
    "income_row=income.replace({'>50K':0,'<=50K':1})\n",
    "scaler=MinMaxScaler()\n",
    "numerical=['age','education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "feature_log_minmax_transform=feature_final\n",
    "feature_log_minmax_transform[numerical]=scaler.fit_transform(feature_log_minmax_transform[numerical])\n",
    "#print(feature_log_minmax_transform.head())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feature_log_minmax_transform,income_row, test_size=.2, random_state=0)\n",
    "sample_100=len(Y_train)\n",
    "sample_10=int(sample_100*.1)\n",
    "sample_1=int(sample_100*.01)\n",
    "def train_predict(learner, sample_size, X_train, Y_train, X_test, Y_test):\n",
    "    result={}\n",
    "    start=time()\n",
    "    learner=learner.fit(X_train[:sample_size],Y_train[:sample_size])\n",
    "    end=time()\n",
    "    result['train_time']=end-start\n",
    "    start=time()\n",
    "    prediction_test=learner.predict(X_test)\n",
    "    prediction_train=learner.predict(X_train[:300])\n",
    "    end=time()\n",
    "    result['prediction_time']=end-start\n",
    "    result['accu_test']=accuracy_score(Y_test, prediction_test)\n",
    "    result['accu_train']=accuracy_score(Y_train[:300],prediction_train)\n",
    "    result['f_train']=fbeta_score(Y_train[:300],prediction_train, beta=.5)\n",
    "    result['f_test']=fbeta_score(Y_test,prediction_test, beta=.5)\n",
    "    print(\"{} {} samples F Score => train: {} test: {}\".format(learner.__class__.__name__, sample_size, round(result['f_train'],2), round(result['f_test'],2)))\n",
    "    return result\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_A=svm.SVC(random_state=7)\n",
    "clf_B=SGDClassifier(random_state=7)\n",
    "clf_C= KNeighborsClassifier()\n",
    "result={}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    result[clf_name] = {}\n",
    "    for i, samples in enumerate([sample_1, sample_10, sample_100]):\n",
    "        result[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, Y_train, X_test, Y_test)\n",
    "#print(result['train_time'])\n",
    "#print(result)\n",
    "#print(income_row)\n",
    "#print(feature_data)\n",
    "#plt.plot(feature_data[skewed[0]],income,'o')\n",
    "#plt.show()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVC': {0: {'train_time': 0.026928186416625977, 'prediction_time': 0.578519344329834, 'accu_test': 0.7562189054726368, 'accu_train': 0.76, 'f_train': 0.7983193277310925, 'f_test': 0.7949790794979079}, 1: {'train_time': 1.7622857093811035, 'prediction_time': 3.881617546081543, 'accu_test': 0.8326147042564953, 'accu_train': 0.8333333333333334, 'f_train': 0.8605919003115264, 'f_test': 0.8649660225100874}, 2: {'train_time': 166.16436409950256, 'prediction_time': 18.30607533454895, 'accu_test': 0.8371475953565506, 'accu_train': 0.8533333333333334, 'f_train': 0.8818770226537219, 'f_test': 0.8783109830433337}}, 'SGDClassifier': {0: {'train_time': 0.003993988037109375, 'prediction_time': 0.00996851921081543, 'accu_test': 0.8143725815367606, 'accu_train': 0.84, 'f_train': 0.8737864077669902, 'f_test': 0.8616291826659354}, 1: {'train_time': 0.013964414596557617, 'prediction_time': 0.010968923568725586, 'accu_test': 0.8044223327805418, 'accu_train': 0.8133333333333334, 'f_train': 0.8686440677966104, 'f_test': 0.8688900499245327}, 2: {'train_time': 0.15259099006652832, 'prediction_time': 0.010972738265991211, 'accu_test': 0.8297401879491432, 'accu_train': 0.8266666666666667, 'f_train': 0.8896797153024911, 'f_test': 0.8926228530534349}}, 'KNeighborsClassifier': {0: {'train_time': 0.0039899349212646484, 'prediction_time': 0.8487675189971924, 'accu_test': 0.8074074074074075, 'accu_train': 0.87, 'f_train': 0.8963815789473685, 'f_test': 0.8577946350043975}, 1: {'train_time': 0.019946813583374023, 'prediction_time': 4.866943597793579, 'accu_test': 0.8195688225538972, 'accu_train': 0.8633333333333333, 'f_train': 0.8940397350993378, 'f_test': 0.8685119180218311}, 2: {'train_time': 1.1099917888641357, 'prediction_time': 25.713223457336426, 'accu_test': 0.8235489220563847, 'accu_train': 0.8833333333333333, 'f_train': 0.9141156462585034, 'f_test': 0.8771979904087691}}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3a2d4e2d704d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vs' is not defined"
     ]
    }
   ],
   "source": [
    "vs.distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
